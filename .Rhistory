pt %>%
filter(`Específ. Estudios` == 1) %>%
View("edu")
pt
pt %>%
filter(`Específ. Estudios` == 1,
question == "edlvpru",
str_detect(coding_esp_maria, "^RU -")) %>%
View("edu")
pt %>%
filter(`Específ. Estudios` == 1,
question == "edlvpru",
str_detect(coding_esp_maria, "^RUS -")) %>%
View("edu")
pt %>%
filter(`Específ. Estudios` == 1,
question == "edlvpru") %>%
View("edu")
pt %>%
filter(`Específ. Estudios` == 1,
question == "edlvpru") %>%
pull(coding)
pt %>%
filter(`Específ. Estudios` == 1,
question == "edlvpru") %>%
pull(coding) %>%
cat()
9 + 6
9 + 4
14 + 6
14 + 4
library(usethis)
devtools::install_github("cimentadaj/coauthornetwork")
library(coauthornetwork)
plot_coauthors(grab_network("citations?user=YA43PbsAAAAJ&hl=en", n_coauthors = 7))
ggplot2::ggsave("../../../Downloads/network.tiff", height=5, width=5, units='in', dpi=600)
ggplot2::ggsave("../../../Downloads/network.tiff", height=8, width=10, units='in', dpi=600)
ggplot2::ggsave("../../../Downloads/network.tiff", height=10, width=12, units='in', dpi=600)
ggplot2::ggsave("../../../Downloads/network.png", height=10, width=12, units='in', dpi=600)
sum(cranlogs::cran_downloads("essurvey", from = "2017-01-01")$count)
sum(cranlogs::cran_downloads("ess", from = "2017-01-01")$count)
haven::read_por("../../../Downloads/ESS1_SI_SDDF.spss/ESS1_SI_SDDF.por")
haven::read_por("../../../Downloads/ESS1_SI_SDDF/ESS1_SI_SDDF.por")
haven::read_sav("../../../Downloads/ESS1_SI_SDDF/ESS1_SI_SDDF.por")
haven::read_sav("../../../Downloads/ESS1_SI_SDDF/ESS1_SI_SDDF.sav")
devtools::session_info()
devtools::install_github("pachamaltese/oec-r-package")
library(oec)
getdata("chl", "chn", 2015)
reprex::reprex({
devtools::install_github("pachamaltese/oec-r-package")
library(oec)
getdata("chl", "chn", 2015)
})
reprex::reprex({
library(oec)
getdata("chl", "chn", 2015)
})
reprex::reprex({
library(oec)
getdata("chl", "chn", 2015)
}, si = TRUE)
debugonce(mean)
my_mean <- function(x) {
x <- x + 1
x
}
my_mean("[")
my_mean <- function(x) {
x <- x + 1
x
}
my_mean("[")
source("../../../Downloads/debug.R")
my_mean <- function(x) {
x <- x + 1
x
}
my_mean("[")
source("../../../Downloads/debug.R")
planets <- "https://raw.githubusercontent.com/rstudio/rstudio-conf/master/2018/Debugging_in_RStudio--Amanda_Gadrow/planets.csv"
read.csv2(planets)
moar_planets <- "https://raw.githubusercontent.com/rstudio/rstudio-conf/master/2018/Debugging_in_RStudio--Amanda_Gadrow/moar_planets.csv"
library(tidyverse)
moar_planets <- "https://raw.githubusercontent.com/rstudio/rstudio-conf/master/2018/Debugging_in_RStudio--Amanda_Gadrow/moar_planets.csv"
planets <- "https://raw.githubusercontent.com/rstudio/rstudio-conf/master/2018/Debugging_in_RStudio--Amanda_Gadrow/planets.csv"
# Separate, flatten, and trim values in the vector
clean <- function(vec) {
values <- strsplit(vec, ",")
flat_values <- unlist(values)
trimmed_values <- str_trim(flat_values)
trimmed_values
}
# Clean vector and get the unique values
uniquify <- function(vec) {
clean_values <- clean(vec)
unique_values <- unique(clean_values)
unique_values
}
source("../../../Downloads/debug.R")
source("../../../Downloads/debug.R", echo = TRUE)
get_climates()
get_climates()
x
x <- as.character(x)
get_climates()
get_climates()
vec
get_climates()
vec
x
x
as.character(x)
x <- as.character(x)
View(get_climates)
source("../../../Downloads/debug.R", echo = TRUE)
get_climates()
get_climates()
source("../../../Downloads/debug.R", echo = TRUE)
get_climates()
source("../../../Downloads/debug.R")
get_climates()
get_climates()
planets
ls
vec
vec
x
split
split <- ",|\\|"
.Internal(strsplit(x, as.character(split), fixed, perl, useBytes))
.Internal(strsplit(x, as.character(split), fixed, perl, useBytes))
values
vec
flat_values
ls
source("../../../Downloads/debug.R")
moar_planets <- "https://raw.githubusercontent.com/rstudio/rstudio-conf/master/2018/Debugging_in_RStudio--Amanda_Gadrow/moar_planets.csv"
planets <- "https://raw.githubusercontent.com/rstudio/rstudio-conf/master/2018/Debugging_in_RStudio--Amanda_Gadrow/planets.csv"
get_climates()
source("../../../Downloads/debug.R")
get_climates()
devtools::install_github("pachamaltese/oec")
library(oec)
oec::country_codes
oec::hs02
oec::hs07
?oec::hs07
?oec::hs92
?oec::sitc
oec::getdata()
?oec::getdata
getdata("chl", "chn", 2015)
?oec::get_data
?oec::get_data
?oec::getdata
?oec::get_data
oec::country_codes
oec::country_codes
oec::hs02
tail(oec::hs02)
?(oec::hs02)
?oec::hs02
tail(oec::hs92)
tail(oec::hs07)
oec
oec::sitc
oec::hs07
name <- "Live bovine"
contains
dplyr::contains
dplyr:::grep_vars
tidyselect:::grep_vars
tidyselect:::matches
tidyselect:::starts_with
tidyselect:::which_vars
namespaceExport
?namespaceExport
nsName <- "stats"
(ns <- asNamespace(nsName)) # <environment: namespace:stats>
ns
environmentName(asNamespace("stats")) # "stats"
getNamespaceInfo(ns, "spec")[["name"]] ## -> "stats"
getNamespaceInfo(ns, "spec")
function(ns) sapply(lsNamespaceInfo(ns), getNamespaceInfo, ns=ns)
allinfoNS <- function(ns) sapply(lsNamespaceInfo(ns), getNamespaceInfo, ns=ns)
allinfoNS()
allinfoNS
getNamespace("oec")
data(package = "oec")
data(package = "oec", verbose = FALSE, list = TRUE)
data(package = "oec", verbose = FALSE)
?data(package = "oec", verbose = FALSE)
names(data(package = "oec", verbose = FALSE))
data(package = "oec")$title
data(package = "oec")$results
data(package = "oec")$results$item
data(package = "oec")$results[, "Item"]
lapply(stringr::str_subset(all_datasets, "^hs"), get)
all_datasets <- data(package = "oec")$results[, "Item"]
lapply(stringr::str_subset(all_datasets, "^hs"), get)
do.call(lapply(stringr::str_subset(all_datasets, "^hs"), get), rbind)
do.call(rbind, lapply(stringr::str_subset(all_datasets, "^hs"), get))
lapply(stringr::str_subset(all_datasets, "^hs"), get)
stringr::str_subset(all_datasets, "^hs")
all_datasets <-
stringr::str_subset(
all_datasets, data(package = "oec")$results[, "Item"]
)
tibble::enframe
lapply(all_datasets, get) %>% enframe() %>% unnest()
library(dplyr)
lapply(all_datasets, get) %>% enframe() %>% unnest()
library(tibble)
lapply(all_datasets, get) %>% enframe() %>% unnest()
library(tidyr)
lapply(all_datasets, get) %>% enframe() %>% unnest()
all_datasets <-
stringr::str_subset(
all_datasets, data(package = "oec")$results[, "Item"]
)
all_datasets <-
stringr::str_subset(
all_datasets, data(package = "oec")$results[, "Item"],
"^hs"
)
all_datasets <-
stringr::str_subset(
all_datasets, data(package = "oec")$results[, "Item"],
"^hs"
)
all_datasets, data(package = "oec")$results[, "Item"]
all_datasets <-
stringr::str_subset(
data(package = "oec")$results[, "Item"],
"^hs"
)
all_datasets
lapply(all_datasets, get) %>% enframe() %>% unnest()
all_datasets
lapply(all_datasets, get) %>% enframe()
lapply(all_datasets, get)
all_datasets <-
stringr::str_subset(
data(package = "oec")$results[, "Item"],
"^hs"
)
stringr::str_subset(
data(package = "oec")$results[, "Item"],
"^hs"
)
lapply(setNames(all_datasets, all_datasets), get) %>% enframe() %>% unnest()
lapply(setNames(all_datasets, all_datasets), get)
enframe
lapply(setNames(all_datasets, all_datasets), get)
all_data <- lapply(all_datastr, get)
all_datastr <-
stringr::str_subset(
data(package = "oec")$results[, "Item"],
"^hs"
)
all_data <- lapply(all_datastr, get)
all_data
lapply(seq_along(all_data), function(index) {all_data[[index]]$type_product <- all_datastr[index]; all_data[[index})
Map(function(x, y) {x$type_product <- y; x}, all_data, all_datastr)
do.call(rbind, Map(function(x, y) {x$type_product <- y; x}, all_data, all_datastr))
?grep
filter(rbined_data, grep(name, product_name, fixed = TRUE))
rbined_data <-
do.call(rbind,
Map(function(x, y) {x$type_product <- y; x}, all_data, all_datastr))
filter(rbined_data, grep(name, product_name, fixed = TRUE))
filter(rbined_data, grepl(name, product_name, fixed = TRUE))
all_datastr %>%
map(get) %>%
map2(all_datastr, ~ {.x$type_product <- .y; .x}}) %>%
filter(grepl(name, product_name, fixed = TRUE))
name <- "Love bovina"
name <- "Love bovine"
all_datastr <-
stringr::str_subset(
data(package = "oec")$results[, "Item"],
"^hs"
)
all_datastr %>%
map(get) %>%
map2(all_datastr, ~ {.x$type_product <- .y; .x}}) %>%
filter(grepl(name, product_name, fixed = TRUE))
all_datastr %>%
map(get)
library(purrr)
all_datastr %>%
map(get) %>%
map2(all_datastr, ~ {.x$type_product <- .y; .x}}) %>%
filter(grepl(name, product_name, fixed = TRUE))
all_datastr %>%
map(get)
all_datastr %>%
map(get) %>%
map2(all_datastr, ~ {.x$type_product <- .y; .x}})
all_datastr %>%
map(get) %>%
map2(all_datastr, ~ {.x$type_product <- .y; .x})
all_datastr %>%
map(get) %>%
map2(all_datastr, ~ {.x$type_product <- .y; .x}) %>%
filter(grepl(name, product_name, fixed = TRUE))
all_datastr %>%
map(get) %>%
map2_dfr(all_datastr, ~ {.x$type_product <- .y; .x}) %>%
filter(grepl(name, product_name, fixed = TRUE))
all_datastr %>%
map(get) %>%
map2_dfr(all_datastr, ~ {.x$type_product <- .y; .x})
name
name <- "Live bovine"
all_datastr %>%
map(get) %>%
map2_dfr(all_datastr, ~ {.x$type_product <- .y; .x}) %>%
filter(grepl(name, product_name, fixed = TRUE))
get_products <- function(name) {
all_datastr <-
stringr::str_subset(
data(package = "oec")$results[, "Item"],
"^hs"
)
all_datastr %>%
map(get) %>%
map2_dfr(all_datastr, ~ {.x$type_product <- .y; .x}) %>%
filter(grepl(name, product_name, fixed = TRUE))
}
get_products("Live bovine")
get_products("Medicine")
get_products("Finance")
get_products("Animals")
get_products("Gold")
get_products <- function(name) {
# Grab all the names of all hs datasets
all_datastr <-
stringr::str_subset(
data(package = "oec")$results[, "Item"],
"^hs"
)
# get the datasets, create the type_product column, bind them all together
# and do the search
all_datastr %>%
map(get) %>%
map2_dfr(all_datastr, ~ {.x$type_product <- .y; .x}) %>%
filter(stringr::str_detect(name, product_name))
}
get_products("Gold")
get_products <- function(name) {
# Grab all the names of all hs datasets
all_datastr <-
stringr::str_subset(
data(package = "oec")$results[, "Item"],
"^hs"
)
# get the datasets, create the type_product column, bind them all together
# and do the search
all_datastr %>%
map(get) %>%
map2_dfr(all_datastr, ~ {.x$type_product <- .y; .x}) %>%
filter(stringr::str_detect(product_name, name))
}
get_products("Gold")
get_products("Animals")
?has_internet
curl::has_internet()
curl::has_internet
jsonlite::fromJSON
curl::curl
?curl::curl
get_products <- function(name) {
# Grab all the names of all hs datasets
all_datastr <-
stringr::str_subset(
data(package = "oec")$results[, "Item"],
"^hs"
)
# get the datasets, create the type_product column, bind them all together
# and do the search
all_datastr %>%
purrr::map(get) %>%
purrr::map2_dfr(all_datastr, ~ {.x$type_product <- .y; .x}) %>%
dplyr::filter(stringr::str_detect(product_name, name))
}
get_products("Gold")
get_products("Animals")
15000 * 60
1000000 / 60
library(lavaan)
# reinstall digavaan
# devtools::install_github("asqm/digavaan")
library(digavaan)
####Final Model
basemetric <- 'tefficacy=~ 1*lkredcc + c(a1,a,a,a,a5,a,a,a,a,a10,a,a,a,a,a15,a,a)*ownrdcc
cefficacy=~ 1*lklmten + c(b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b)*gvsrdcc
tefficacy ~~ tefficacy
tefficacy ~ 1
cefficacy ~~ cefficacy
cefficacy ~ 1
gvsrdcc ~~ gvsrdcc
lkredcc ~~ lkredcc
lklmten ~~ lklmten
ownrdcc ~~ ownrdcc
gvsrdcc ~ c(c,c,c,c,c5,c,c,c,c,c,c,c,c,c,c,c,c)*1
ownrdcc ~ c(d1,d,d,d,d5,d,d,d,d,d10,d,d,d,d,d15,d,d17)*1
tefficacy ~~ cefficacy
'
noCZ <- read.csv("../../../Downloads/noCZ.csv")
m1 <-lavaan(basemetric, data=noCZ,
group="cntry",
auto.fix.first=F,
auto.var=F,
auto.cov.y=F)
group_qsscore(m1)
group_qsscore(m1, c("AT", "NL", "PL"))
# reinstall digavaan
devtools::install_github("asqm/digavaan")
# reinstall digavaan
# devtools::install_github("asqm/digavaan")
library(digavaan)
basemetric <- 'tefficacy=~ 1*lkredcc + c(a1,a,a,a,a5,a,a,a,a,a10,a,a,a,a,a15,a,a)*ownrdcc
cefficacy=~ 1*lklmten + c(b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b)*gvsrdcc
tefficacy ~~ tefficacy
tefficacy ~ 1
cefficacy ~~ cefficacy
cefficacy ~ 1
gvsrdcc ~~ gvsrdcc
lkredcc ~~ lkredcc
lklmten ~~ lklmten
ownrdcc ~~ ownrdcc
gvsrdcc ~ c(c,c,c,c,c5,c,c,c,c,c,c,c,c,c,c,c,c)*1
ownrdcc ~ c(d1,d,d,d,d5,d,d,d,d,d10,d,d,d,d,d15,d,d17)*1
tefficacy ~~ cefficacy
'
noCZ <- read.csv("../../../Downloads/noCZ.csv")
m1 <-lavaan(basemetric, data=noCZ,
group="cntry",
auto.fix.first=F,
auto.var=F,
auto.cov.y=F)
library(lavaan)
m1 <-lavaan(basemetric, data=noCZ,
group="cntry",
auto.fix.first=F,
auto.var=F,
auto.cov.y=F)
group_qsscore(m1)
# reinstall digavaan
devtools::install_github("asqm/digavaan")
library(lavaan)
# reinstall digavaan
# devtools::install_github("asqm/digavaan")
library(digavaan)
basemetric <- 'tefficacy=~ 1*lkredcc + c(a1,a,a,a,a5,a,a,a,a,a10,a,a,a,a,a15,a,a)*ownrdcc
cefficacy=~ 1*lklmten + c(b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b)*gvsrdcc
tefficacy ~~ tefficacy
tefficacy ~ 1
cefficacy ~~ cefficacy
cefficacy ~ 1
gvsrdcc ~~ gvsrdcc
lkredcc ~~ lkredcc
lklmten ~~ lklmten
ownrdcc ~~ ownrdcc
gvsrdcc ~ c(c,c,c,c,c5,c,c,c,c,c,c,c,c,c,c,c,c)*1
ownrdcc ~ c(d1,d,d,d,d5,d,d,d,d,d10,d,d,d,d,d15,d,d17)*1
tefficacy ~~ cefficacy
'
noCZ <- read.csv("../../../Downloads/noCZ.csv")
m1 <-lavaan(basemetric, data=noCZ,
group="cntry",
auto.fix.first=F,
auto.var=F,
auto.cov.y=F)
group_qsscore(m1)
group_qsscore(m1, c("AT", "NL", "PL"))
group_qsscore(m1, "IS")
devtools::install_github("ewenharrison/finalfit")
library(finalfit)
library(dplyr)
# Load example dataset, modified version of survival::colon
data(colon_s)
# Table 1 - Patient demographics ----
explanatory = c("age", "age.factor", "sex.factor", "obstruct.factor")
dependent = "perfor.factor"
colon_s %>%
summary_factorlist(dependent, explanatory, p=TRUE)
27500 / 12
559 - 442
585 - 442
(585 - 442) + 62
(585 - 442) + 60
450 + 200 + 70 + 54 + 100
450 + 200 + 70 + 54 + 100 + 300
450 + 200 + 70 + 54 + 100 + 366 + 15
450 + 200 + 70 + 54 + 100 + 366 + 15
1366 - (450 + 200 + 70 + 54 + 100 + 366 + 15)
1366 - (450 + 200 + 70 + 54 + 100 + 366 + 15)
exp(0.105)
80 / 10
0.80 / 0.10
sqrt(0.80 / 0.10)
log(0.80 / 0.10)
0.10
exp(0.10)
paste(c(rep(NA, 8), "Batman!"), collapse=" ")
getwd()
setwd("../all_repos/datos_gob/")
usethis::create_project(",")
usethis::create_project(".")
